{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "github_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
    "\n",
    "df = pd.read_csv(f'{github_url}?raw=1')\n",
    "\n",
    "df_300 = df.iloc[:300]\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42244658"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "embedding_vector = embedding_model.encode(df_300['answer_llm'].iloc[0])\n",
    "\n",
    "embedding_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def normalize_vector(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    return 0 if norm==0 else (v / norm)\n",
    "\n",
    "def compute_similarity_percentile(df, normalize=False, percentile=75):\n",
    "    evaluations = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        answer_llm = row['answer_llm']\n",
    "        answer_orig = row['answer_orig']\n",
    "    \n",
    "        if normalize:\n",
    "            embedding_llm = normalize_vector(embedding_model.encode(answer_llm))\n",
    "            embedding_orig= normalize_vector(embedding_model.encode(answer_orig))\n",
    "        else:\n",
    "            embedding_llm = embedding_model.encode(answer_llm)\n",
    "            embedding_orig = embedding_model.encode(answer_orig)\n",
    "    \n",
    "        score = np.dot(embedding_llm, embedding_orig)\n",
    "    \n",
    "        evaluations.append(score)\n",
    "\n",
    "    return np.percentile(evaluations, percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [02:18,  2.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.674312114715576"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_similarity_percentile(df_300, False, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [02:21,  2.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8362347930669785"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_similarity_percentile(df_300, True, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 score for ROUGE-1 is: 0.45454544954545456\n",
      "The average F1 score between ROUGE-1, ROUGE-2, and ROUGE-L is: 0.35490034990035496\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "r = df_300[df_300['document'] == '5170565b'].iloc[0]\n",
    "\n",
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "\n",
    "rouge_1_f1 = scores['rouge-1']['f']\n",
    "\n",
    "print(\"The F1 score for ROUGE-1 is:\", rouge_1_f1)\n",
    "\n",
    "rouge_2_f1 = scores['rouge-2']['f']\n",
    "rouge_l_f1 = scores['rouge-l']['f']\n",
    "\n",
    "average_f1_score = (rouge_1_f1 + rouge_2_f1 + rouge_l_f1) / 3\n",
    "\n",
    "print(\"The average F1 score between ROUGE-1, ROUGE-2, and ROUGE-L is:\", average_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average ROUGE-2 F1 score across all records is: 0.20696501983423318\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "def compute_rouge_scores(row):\n",
    "    scores = rouge_scorer.get_scores(row['answer_llm'], row['answer_orig'])[0]\n",
    "    return {\n",
    "        'document': row['document'],\n",
    "        'rouge_1_f1': scores['rouge-1']['f'],\n",
    "        'rouge_2_f1': scores['rouge-2']['f'],\n",
    "        'rouge_l_f1': scores['rouge-l']['f']\n",
    "    }\n",
    "\n",
    "scores_df = pd.DataFrame(list(map(compute_rouge_scores, df_300.to_dict('records'))))\n",
    "\n",
    "average_rouge_2_f1 = scores_df['rouge_2_f1'].mean()\n",
    "\n",
    "print(\"The average ROUGE-2 F1 score across all records is:\", average_rouge_2_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
